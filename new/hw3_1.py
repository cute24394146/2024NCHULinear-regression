# -*- coding: utf-8 -*-
"""HW3-1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mmELmuScgFtFlDtUdt3OP4NhGHnw_R6M
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from matplotlib.font_manager import FontProperties

# Install Chinese fonts to support Chinese display
!apt-get install -y fonts-noto-cjk

# Set up the Chinese font for displaying labels
chinese_font = FontProperties(fname='/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc')

# 1. Data Generation
np.random.seed(0)  # For reproducibility
X = np.random.randint(0, 1001, 300).reshape(-1, 1)
Y = np.where((X > 500) & (X < 800), 1, 0).ravel()

# 2. Split dataset into training and testing sets
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)

# 3. Logistic Regression Model
logistic_model = LogisticRegression()
logistic_model.fit(X_train, Y_train)
y1 = logistic_model.predict(X_test)

# 4. SVM Model
svm_model = SVC(probability=True)
svm_model.fit(X_train, Y_train)
y2 = svm_model.predict(X_test)

# 5. Visualization
plt.figure(figsize=(14, 6))

# First plot: Logistic Regression
plt.subplot(1, 2, 1)
plt.scatter(X_test, Y_test, color='blue', label='Actual Labels')
plt.scatter(X_test, y1, color='red', label='Logistic Regression Prediction', alpha=0.5)
plt.title('Logistic Regression Prediction', fontproperties=chinese_font)
plt.xlabel('X', fontproperties=chinese_font)
plt.ylabel('Y', fontproperties=chinese_font)
plt.legend(prop=chinese_font)

# Second plot: SVM
plt.subplot(1, 2, 2)
plt.scatter(X_test, Y_test, color='blue', label='Actual Labels')
plt.scatter(X_test, y2, color='green', label='SVM Prediction', alpha=0.5)
plt.title('SVM Prediction', fontproperties=chinese_font)
plt.xlabel('X', fontproperties=chinese_font)
plt.ylabel('Y', fontproperties=chinese_font)
plt.legend(prop=chinese_font)

plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split

# 1. Generate 300 random variables X(i) in the range [0, 1000]
np.random.seed(42)  # for reproducibility
X = np.random.uniform(0, 1000, 300).reshape(-1, 1)
Y = np.where((X >= 500) & (X <= 800), 1, 0).ravel()

# 2. Split data for training and testing
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)

# 3. Logistic Regression
logistic_model = LogisticRegression()
logistic_model.fit(X_train, Y_train)
y1_pred = logistic_model.predict(X)

# 4. Support Vector Machine (SVM)
svm_model = SVC(kernel='linear', probability=True)
svm_model.fit(X_train, Y_train)
y2_pred = svm_model.predict(X)

# Decision boundaries for Logistic Regression and SVM
x_range = np.linspace(0, 1000, 1000).reshape(-1, 1)
logistic_boundary = logistic_model.predict_proba(x_range)[:, 1]
svm_decision = svm_model.decision_function(x_range)

# 5. Visualization
plt.figure(figsize=(14, 6))

# Plot 1: Logistic Regression
plt.subplot(1, 2, 1)
plt.scatter(X, Y, color='blue', label='Actual Data', alpha=0.6)
plt.scatter(X, y1_pred, color='red', label='Logistic Regression Predictions', alpha=0.6)
plt.plot(x_range, logistic_boundary, color='green', label='Logistic Decision Boundary', linewidth=2)
plt.title('Logistic Regression')
plt.xlabel('X')
plt.ylabel('Y')
plt.legend()

# Plot 2: SVM
plt.subplot(1, 2, 2)
plt.scatter(X, Y, color='blue', label='Actual Data', alpha=0.6)
plt.scatter(X, y2_pred, color='orange', label='SVM Predictions', alpha=0.6)
plt.axvline(x=svm_model.support_vectors_[0], color='green', linestyle='--', label='SVM Decision Boundary')
plt.axvline(x=svm_model.support_vectors_[-1], color='green', linestyle='--')
plt.title('Support Vector Machine (SVM)')
plt.xlabel('X')
plt.ylabel('Y')
plt.legend()

plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.svm import SVC

# 1. 生成數據
np.random.seed(42)
X = np.random.uniform(0, 1000, 300).reshape(-1, 1)
Y = np.where((X >= 500) & (X <= 800), 1, 0).ravel()

# 2. 訓練 SVM
svm_model = SVC(kernel='rbf', C=1, gamma=0.01, probability=True)
svm_model.fit(X, Y)

# 3. 可視化
x_range = np.linspace(0, 1000, 1000).reshape(-1, 1)
y_decision = svm_model.decision_function(x_range)

plt.figure(figsize=(8, 6))
plt.scatter(X, Y, color='blue', label='Actual Data', alpha=0.6, marker='x')
plt.plot(x_range, svm_model.predict(x_range), color='green', label='SVM (RBF) Predictions')
plt.axvline(x=500, color='black', linestyle='--', label='SVM (RBF) Decision Boundary')
plt.axvline(x=800, color='black', linestyle='--')
plt.title("SVM Classification with RBF Kernel")
plt.xlabel("X")
plt.ylabel("Y / Y2")
plt.legend()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC

# 1. 生成數據
np.random.seed(42)
X = np.random.uniform(0, 1000, 300).reshape(-1, 1)
Y = np.where((X >= 500) & (X <= 800), 1, 0).ravel()

# 2. Logistic Regression 模型
logistic_model = LogisticRegression()
logistic_model.fit(X, Y)
y1_pred = logistic_model.predict(X)

# 3. SVM 模型
svm_model = SVC(kernel='linear', probability=True)
svm_model.fit(X, Y)
y2_pred = svm_model.predict(X)

# 4. 可視化結果
plt.figure(figsize=(14, 6))

# 左圖：Logistic Regression 結果
plt.subplot(1, 2, 1)
plt.scatter(X, Y, color='blue', label='Actual Data', alpha=0.6, marker='o')
plt.scatter(X, y1_pred, color='red', label='Logistic Regression Predictions', alpha=0.6, marker='x')
plt.title('Logistic Regression')
plt.xlabel('X')
plt.ylabel('Y')
plt.legend()

# 右圖：SVM 結果
plt.subplot(1, 2, 2)
plt.scatter(X, Y, color='blue', label='Actual Data', alpha=0.6, marker='o')
plt.scatter(X, y2_pred, color='orange', label='SVM Predictions', alpha=0.6, marker='x')
plt.title('Support Vector Machine (SVM)')
plt.xlabel('X')
plt.ylabel('Y')
plt.legend()

plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Step 1: Business Understanding
# Goal: Classify binary outcomes using Logistic Regression and SVM to analyze classification performance and decision boundaries.

# Step 2: Data Understanding
# Generate data
np.random.seed(42)
X = np.random.uniform(0, 1000, 300).reshape(-1, 1)
Y = np.where((X > 500) & (X < 800), 1, 0).ravel()

# Step 3: Data Preparation
# Ensure reproducibility and appropriate data structure
print(f"Generated Data: X.shape = {X.shape}, Y.shape = {Y.shape}")

# Step 4: Modeling
# Logistic Regression Model
logistic_model = LogisticRegression()
logistic_model.fit(X, Y)
Y1 = logistic_model.predict(X)  # Predictions from Logistic Regression

# SVM Model with RBF Kernel for non-linear decision boundaries
svm_rbf_model = SVC(kernel='rbf', C=1, gamma=0.01, probability=True)
svm_rbf_model.fit(X, Y)
Y2_rbf = svm_rbf_model.predict(X)  # Predictions from SVM (RBF)

# SVM Model with Linear Kernel for comparison
svm_linear_model = SVC(kernel='linear', probability=True)
svm_linear_model.fit(X, Y)
Y2_linear = svm_linear_model.predict(X)

# Decision boundaries for visualization
x_range = np.linspace(0, 1000, 1000).reshape(-1, 1)
logistic_boundary = logistic_model.predict_proba(x_range)[:, 1] >= 0.5
svm_rbf_boundary = svm_rbf_model.decision_function(x_range)
svm_linear_boundary = svm_linear_model.decision_function(x_range)

# Step 5: Evaluation
# Accuracy on training data
logistic_accuracy = accuracy_score(Y, Y1)
svm_rbf_accuracy = accuracy_score(Y, Y2_rbf)
svm_linear_accuracy = accuracy_score(Y, Y2_linear)

print(f"Logistic Regression Accuracy: {logistic_accuracy:.2f}")
print(f"SVM (RBF Kernel) Accuracy: {svm_rbf_accuracy:.2f}")
print(f"SVM (Linear Kernel) Accuracy: {svm_linear_accuracy:.2f}")

# Step 6: Deployment (Visualization)
plt.figure(figsize=(18, 6))

# Logistic Regression Visualization
plt.subplot(1, 3, 1)
plt.scatter(X, Y, color='blue', label='Actual Data', alpha=0.6, marker='x')
plt.plot(X, Y1, 'ro', label='Logistic Predictions', markersize=2)
plt.plot(x_range, logistic_boundary, 'k--', label='Logistic Decision Boundary')
plt.title(f"Logistic Regression (Accuracy: {logistic_accuracy:.2f})")
plt.xlabel("X")
plt.ylabel("Y")
plt.legend()

# SVM with RBF Kernel Visualization
plt.subplot(1, 3, 2)
plt.scatter(X, Y, color='blue', label='Actual Data', alpha=0.6, marker='x')
plt.plot(X, Y2_rbf, 'go', label='SVM (RBF) Predictions', markersize=2)
plt.plot(x_range, (svm_rbf_boundary >= 0).astype(int), 'k--', label='RBF Decision Boundary')
plt.title(f"SVM with RBF Kernel (Accuracy: {svm_rbf_accuracy:.2f})")
plt.xlabel("X")
plt.ylabel("Y")
plt.legend()

# SVM with Linear Kernel Visualization
plt.subplot(1, 3, 3)
plt.scatter(X, Y, color='blue', label='Actual Data', alpha=0.6, marker='x')
plt.plot(X, Y2_linear, 'mo', label='SVM (Linear) Predictions', markersize=2)
plt.axvline(x=svm_linear_model.support_vectors_[0], color='black', linestyle='--', label='Linear Decision Boundary')
plt.axvline(x=svm_linear_model.support_vectors_[-1], color='black', linestyle='--')
plt.title(f"SVM with Linear Kernel (Accuracy: {svm_linear_accuracy:.2f})")
plt.xlabel("X")
plt.ylabel("Y")
plt.legend()

plt.tight_layout()
plt.show()